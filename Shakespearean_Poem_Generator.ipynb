{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d882ee62",
   "metadata": {},
   "source": [
    "# Character Level Langauge Model\n",
    "\n",
    "## Writing Like Shakespeare\n",
    "\n",
    "This notebook is the implementation of character-level text generation model which is used to generate Shakespearean poem. A colloection of Shakespearean poems was used as a training data. Using LSTM cells, the model can learn longer-term dependencies that span many characters in the text--e.g., where a character appearing somewhere a sequence can influence what should be a different character, much later in the sequence.\n",
    "\n"   ]
  },
  {
   "cell_type": "markdown",
   "id": "44557944",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c65b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from shakespeare_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4330a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "246/246 [==============================] - 57s 212ms/step - loss: 2.5682\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 54s 221ms/step - loss: 2.0281\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 52s 212ms/step - loss: 1.9342\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 53s 216ms/step - loss: 1.8827\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 48s 197ms/step - loss: 1.8483\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 47s 191ms/step - loss: 1.8196\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 49s 198ms/step - loss: 1.7971\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 46s 187ms/step - loss: 1.7639\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 44s 180ms/step - loss: 1.7517\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 48s 195ms/step - loss: 1.7338\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 50s 202ms/step - loss: 1.7097\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 50s 205ms/step - loss: 1.6969\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 50s 202ms/step - loss: 1.6794\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 50s 201ms/step - loss: 1.6536\n",
      "Epoch 15/20\n",
      "246/246 [==============================] - 50s 203ms/step - loss: 1.6362\n",
      "Epoch 16/20\n",
      "246/246 [==============================] - 49s 197ms/step - loss: 1.6224\n",
      "Epoch 17/20\n",
      "246/246 [==============================] - 49s 199ms/step - loss: 1.6070\n",
      "Epoch 18/20\n",
      "246/246 [==============================] - 51s 206ms/step - loss: 1.5886\n",
      "Epoch 19/20\n",
      "246/246 [==============================] - 49s 201ms/step - loss: 1.5761\n",
      "Epoch 20/20\n",
      "246/246 [==============================] - 59s 240ms/step - loss: 1.5577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23e3998c640>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y, batch_size=128, epochs=20, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e1ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: The moon whispered secrets to the sea\n",
      "\n",
      "\n",
      "Here is your poem: \n",
      "\n",
      "The moon whispered secrets to the sea's dight\n",
      "un berite makoon of wateted love's in them-bund,\n",
      "which more for mare more dowl with thy sacm,\n",
      "of bpael, atite though mine on mine than apcased:\n",
      "then they all other jodgey hemdite,\n",
      "though i bemreping i were as by,\n",
      "hawl and wherione's cweething plef, your dowh,\n",
      " \n",
      "and bey and dear worthous coult, how the jeceflease.\n",
      "sul thy by thee which that make brank my,\n",
      "depily i ecdethe on thine a miver "
     ]
    }
   ],
   "source": [
    "generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b39ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
